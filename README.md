아래는 2023 한국교육공학회 춘계학술대회 <인공지능 시대, 교육공학의 새로운 접근 방향> 포스터 세션에서 발표한 내용으로, 본문 마지막에는 사용한 코드를 함께 정리하였다. 

### 1. 서론

* 최근 인공지능에 대한 교육학계의 관심이 높아지고 있다. 그 중 인공지능의 한 분야인 자연어처리는 ChatGPT의 등장으로 크게 주목 받고 있는 기술이다. 한편, 자연어처리와 관련해 교육학계에서는 이것의 교육적 활용에 대해 논의를 시작한 단계에 있으며, 자연어처리 기술을 적용해 교육 데이터를 분석한 연구는 다소 부족한 실정이다. 

* 이에 본 연구는 딥러닝 기반의 KoBERT를 활용하여, 학생 수업 관찰기록 텍스트 데이터를 바탕으로 학생의 역량(자기관리, 대인관계, 시민, 문제해결역량) 점수를 예측하는 다중분류모델을 개발함으로써, 자연어처리 기술을 적용한 교육 연구의 저변을 확대하는 데 기여하고자 한다.

### 2. BERT, KoBERT

* BERT(Bidirectional Encoder Representations from Transformers)는 2018년 구글에서 발표한 임베딩 모델로서, 트랜스포머 모델을 기반으로 한다. 

* BERT는 크게 사전 학습(pre-training)과 파인 튜닝(fine-tuning)의 두 단계로 진행되는데, 대용량의 언어 데이터를 바탕으로 이미 학습(사전 학습)된 모델을, 해결하고자 하는 목표에 맞게 미세 조정(파인 튜닝)하는 과정을 포함한다. 따라서, BERT는 파인 튜닝을 통해 적은 데이터와 짧은 시간으로 학습이 가능하다는 장점을 지닌다. 

* 구체적으로, 사전 학습은 ‘마스크 언어 모델링(MLM)’과 ‘다음 문장 예측(NSP)’에 대한 학습으로 이루어지며, 파인 튜닝은 다운스트림 태스크(예. 텍스트 분류, 질의 응답 등)의 성격에 따라 BERT 구조 뒤에 레이어를 추가하거나, 파라미터 조정을 통해 가중치를 업데이트 하는 과정을 포함한다(이진기, 2022; Ravichandiran, 2021). 

* 본 연구에서는 SKTBrain에서 대규모의 한국어 말뭉치를 학습시킴으로써, 한국어에 특화되도록 개발한 BERT 모델인 KoBERT를 활용하였다. 

### 3. 데이터 수집 ∙ 전처리 및 모델 학습<br/>
**1) 데이터 수집 및 설명**

  * AI Hub에서 제공한 ‘학생 청소년 핵심역량분석 교육 데이터’를 사용하였으며, 원천 데이터는 다음과 같이 개별 데이터셋으로 구성되었다: (1)학생 정보(성별, 지역, 학교급, 학년 등), (2)수업 정보(수업 성격, 과제 유형, 교과목정보 등), (3)학생관찰기록 텍스트 및 역량 별 점수 데이터셋

  * 최종 분석을 위해 개별 데이터셋을 병합하고, 그 중 고등학생 데이터를 선별하였으며, 데이터 크기는 11,173건에 달했다.

**2) 데이터 전처리**  
<br>(1) 피처 셀렉션 (Feature selection)<br/>

* 유용한 피처에 집중하여 모델의 성능을 높이고자, 학생관찰기록 텍스트 데이터(Student assessment)와 함께 수업 정보와 관련된 데이터 Program_category, Mission_category, Subject_category를 모델의 피처로 활용하였다. 

* 수업의 성격 및 목표에 따라 해당 수업에서 발현될 수 있는 학생의 역량 유형과 역량 수준이 다를 수 있다는 가정 하에 위와 같이 피처를 선정하였다. 

* 형태소(일반 명사)의 빈도를 분석해 본 결과, 위와 같은 가정이 충족될 수 있음을 확인하였다. 이를 테면, 수업 과제 유형 Mission_category 피처에 해당하는 데이터가 '도와주기' 일 때, 학생관찰기록 텍스트 데이터 즉, Student assessment 피처에서 출현 빈도가 높은 명사는 '공동체', '배려', '팀원' 등으로 나타났다.

(2) 클래스 불균형(Class Imbalance) 해결

* 데이터 탐색적 분석 결과, 클래스 불균형이 다소 심한 문제가 있어 5개의 클래스(1: 매우 낮음, 2: 낮음, 3: 관측 안됨, 4: 높음, 5: 매우 높음)를 3개의 클래스(0: 매우 낮음, 낮음, 1: 관측 안됨, 2: 높음, 매우 높음)로 일차 재구성하였다. 
* 그럼에도 불구하고, 클래스 불균형 문제가 해소되지 않은 관계로 대표적인 오버샘플링 기법인 SMOTE를 적용하여, 소수 클래스의 샘플 개수를 조정해 데이터셋의 균형을 도모하였다. 그 결과, 클래스별 분포는 아래 그림과 같다.  <br/>
<br><img src="/assets/images/oversamp.png" width="100%" height="100%" title="oversampling"/>  

(3) 데이터셋 재구조화

* 기존 데이터셋은 역량 유형이 4개의 컬럼으로, 각 역량 별 점수가 컬럼 값으로 구성 되었으나, 역량 유형 또한 새로운 피처로 사용 가능하도록 데이터셋을 재구조화 했다. 이를 통해, 데이터 증식 및 모델 1개로 4가지 역량에 대한 점수를 분류하는 효과를 얻을 수 있었다. 
* 최종 데이터셋은 아래 표와 같으며, Program_category, Mission_category, Subject_concept, Student_assessment, Label이 모델의 피처로 활용되었으며, Score는 모델의 타겟이다. (Label 컬럼의 컬럼 값 1은 자기관리역량, 2는 대인관계역량, 3은 시민역량, 4는 문제해결역량을 의미한다.)  

    |Program_category|Mission_category|Subject_concept|Student_assessment|Label|Score|
    |:------:|:---:|:---:|:---:|:---:|:---:|
    |진로탐색|실습/연습|배려|집중력 및 공감능력이 높은 것으로 판단됨|1|2|
    |진로탐색|실습/연습|배려|집중력 및 공감능력이 높은 것으로 판단됨|2|1|
    |진로탐색|실습/연습|배려|집중력 및 공감능력이 높은 것으로 판단됨|3|2|
    |진로탐색|실습/연습|배려|집중력 및 공감능력이 높은 것으로 판단됨|4|0|

**3) 모델 학습**  

* 모델 학습은 Google Colab Pro 환경에서 진행하였고, KoBERT의 PyTorch API를 활용하였다. 학습 데이터와 테스트 데이터는 8:2의 비율로 구성하였다.
* 본 연구 목표인 분류 문제를 수행하고자, BertClassifier를 활용해 파인 튜닝 하였다. KoBERT는 768차원의 벡터를 출력하므로, 은닉층(hidden layer)의 뉴런 개수(hidden_size)는 그대로 768을 사용하였고, 역량 점수인 클래스는 3개로 구분(0, 1, 2)되므로 클래스의 수(num_classes)는 3으로 설정하였다. 모델 성능 향상을 위해 차례로 256차원, 128 차원을 출력하는 두 개의 은닉층을 추가하였으며, 은닉층에서의 활성화 함수는 ReLU로 설정하였다. 마지막으로, 학습된 모델의 Loss를 측정하기 위해 다중분류 모델의 대표적 손실 함수인 교차 엔트로피(Cross Entropy)를 사용하였으며, 모델의 최적화 함수로는 Adam을 사용하였다. 
* 본 연구에서 지정한 모델의 하이퍼 파라미터 값은 아래 표에 정리하였다. 
  
    |하이퍼 파라미터|하이퍼 파라미터 값|
    |:------:|:---:|
    |max_len|256|
    |batch_size|40|
    |warmup_ratio|0.1|
    |num_epochs|50|
    |learning_rate|5e-5|
    |dr_rate|0.3|

* 아래 그림에서 점선으로 & 회색 색상으로 표시한 부분이 본 연구의 모델 학습에 해당한다.   
<br>![model training](https://github.com/kina-park/Student_competency_score_classification_model_using_KoBert/assets/129723313/141c37ce-d5b1-4080-afa0-c839a09aa89b)

### 4. 모델 평가

* 정확도(%) = (올바르게 예측한 테스트 데이터의 개수 / 전체 테스트 데이터의 개수) X 100
* 본 연구의 모델 학습 결과, 테스트 데이터의 정확도는 약 78.20%로 나타났다. 
* 참고로 AI Hub에서는 원천 데이터의 더 다양한 피처를 포함하여 MLP, KoBERT 모델을 결합한 앙상블 기법의 모델을 제시하였으며, 테스트 데이터의 정확도는 약 69.8%로 나타나, 본 연구의 모델이 더 우수한 성능을 보인 점을 확인하였다. 

### 5. 결론 

* 본 연구는 교육적 맥락에서 KoBERT를 활용하여 다중분류모델을 개발하고, 약 78.20%의 비교적 높은 수준의 모델 정확도를 구현함으로써, KoBERT를 활용한 자연어처리 기술의 교육적 활용 가능성을 확대하였다는 점에서 의의가 있다. 
* 최근 일부 해외 대학의 경우 신입생 선발과정에 있어 인공지능 도입을 시작하였으며, 국내에서도 관련 논의가 진행된 바 있다(권정민 외, 2021). 따라서, 본 연구에서 구현한 교사의 학생평가 데이터를 바탕으로 학생의 역량을 예측(분류)하는 기술은 앞으로 입학과 관련한 대학기관의 의사결정에 실질적 기여를 할 수 있을 것으로 기대된다. 
